{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p20nYqnskagD",
        "outputId": "2617de79-aefe-4b5e-932c-373a90e97bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "The environment setup is complete.\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import math\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import io\n",
        "from google.colab import files\n",
        "print(\"The environment setup is complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preparing to upload the file.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "filename = 'Arrest_Data_from_2010_to_2019.csv'\n",
        "\n",
        "\n",
        "if filename in uploaded:\n",
        "    print(f\"Successfully uploaded the file: {filename}\")\n",
        "\n",
        "\n",
        "    df = pd.read_csv(io.BytesIO(uploaded[filename]))\n",
        "    print(f\"Data shape: {df.shape}\")\n",
        "    print(f\"Column name: {list(df.columns)}\")\n",
        "\n",
        "\n",
        "    print(f\"\\n Data preview:\")\n",
        "    print(df.head(3))\n",
        "\n",
        "else:\n",
        "    print(\"File upload failed. Please check if the file name is correct.\")\n",
        "    print(f\"The uploaded files: {list(uploaded.keys())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "4Oi4l4NqlM3C",
        "outputId": "3d2c7d16-1685-4663-df31-d6e8b1d2d0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing to upload the file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-94e20029-d32b-4b36-914b-1c82f47db49d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-94e20029-d32b-4b36-914b-1c82f47db49d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Arrest_Data_from_2010_to_2019.csv to Arrest_Data_from_2010_to_2019.csv\n",
            "Successfully uploaded the file: Arrest_Data_from_2010_to_2019.csv\n",
            "Data shape: (1310127, 17)\n",
            "Column name: ['Report ID', 'Arrest Date', 'Time', 'Area ID', 'Area Name', 'Reporting District', 'Age', 'Sex Code', 'Descent Code', 'Charge Group Code', 'Charge Group Description', 'Arrest Type Code', 'Charge', 'Charge Description', 'Address', 'Cross Street', 'Location']\n",
            "\n",
            " Data preview:\n",
            "   Report ID Arrest Date    Time  Area ID  Area Name  Reporting District  Age  \\\n",
            "0  191811472  05/03/2019  1700.0       18  Southeast                1802   23   \n",
            "1    5614161  04/29/2019  1040.0        8    West LA                 842   41   \n",
            "2    5615197  04/30/2019   615.0        6  Hollywood                 663   27   \n",
            "\n",
            "  Sex Code Descent Code  Charge Group Code Charge Group Description  \\\n",
            "0        F            B                NaN                      NaN   \n",
            "1        M            H                3.0                  Robbery   \n",
            "2        M            O                5.0                 Burglary   \n",
            "\n",
            "  Arrest Type Code     Charge Charge Description  \\\n",
            "0                M  653.22 PC                NaN   \n",
            "1                F      211PC            ROBBERY   \n",
            "2                F      459PC           BURGLARY   \n",
            "\n",
            "                                    Address Cross Street              Location  \n",
            "0                                      91ST     FIGUEROA  (33.9543, -118.2827)  \n",
            "1  11600    WILSHIRE                     BL          NaN  (34.0508, -118.4592)  \n",
            "2                                   LA BREA    LEXINGTON  (34.0907, -118.3384)  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data preprocessing\")\n",
        "df['Arrest Date'] = pd.to_datetime(df['Arrest Date'], errors='coerce')\n",
        "df = df[df['Arrest Date'] < '2019-01-01']\n",
        "if 'Location' in df.columns:\n",
        "    location_split = df['Location'].str.extract(r'\\(([^,]+),\\s*([^)]+)\\)')\n",
        "    df['Latitude'] = pd.to_numeric(location_split[0], errors='coerce')\n",
        "    df['Longitude'] = pd.to_numeric(location_split[1], errors='coerce')\n",
        "    df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "    print({df.shape})\n",
        "    print(f\" Date range: {df['Arrest Date'].min()} to {df['Arrest Date'].max()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFKcYH0ZmqLe",
        "outputId": "fdb38fc5-6c1d-4dc1-9f18-b910121907e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessing\n",
            "{(1231627, 19)}\n",
            " Date range: 2010-01-01 00:00:00 to 2018-12-31 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def haversine_distance(lat1, lon1, lat2, lon2, earth_radius=6371):\n",
        "  lat1_rad = math.radians(lat1)\n",
        "  lon1_rad = math.radians(lon1)\n",
        "  lat2_rad = math.radians(lat2)\n",
        "  lon2_rad = math.radians(lon2)\n",
        "\n",
        "  delta_lat = lat2_rad - lat1_rad\n",
        "  delta_lon = (lon2_rad - lon1_rad) * math.cos((lat1_rad + lat2_rad) / 2)\n",
        "\n",
        "  distance = earth_radius * math.sqrt(delta_lat**2 + delta_lon**2)\n",
        "  return distance\n"
      ],
      "metadata": {
        "id": "bL7Fsc4joReU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2018 = df[df['Arrest Date'].dt.year == 2018]\n",
        "q1_answer = len(df_2018)\n",
        "print(f\"Q1.2018 arrestees bookings: {q1_answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx5b_-1Jo8bB",
        "outputId": "71341ff4-a7f5-4c75-9464-bb1af76c78c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1.2018 arrestees bookings: 104277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "area_counts = df_2018['Area ID'].value_counts()\n",
        "q2_answer = area_counts.iloc[0]\n",
        "print(f\"Q2.The number of bookings of arrestees in the most arrests area in 2018: {q2_answer}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjzQyb7XpmdF",
        "outputId": "b89453b1-3d72-4593-d2be-2eeaff74961d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q2.The number of bookings of arrestees in the most arrests area in 2018: 10951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_charges = ['Vehicle Theft', 'Robbery', 'Burglary', 'Receive Stolen Property']\n",
        "filtered_df = df_2018[df_2018['Charge Group Description'].isin(target_charges)]\n",
        "filtered_df = filtered_df.dropna(subset=['Age'])\n",
        "q3_answer = filtered_df['Age'].quantile(0.95)\n",
        "print(f\"Q3. The  95% quantile age of the specific accusation group: {q3_answer:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3K2W2GVqCsx",
        "outputId": "ee7f56ef-f974-4291-ad5f-1143aab90c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q3. The  95% quantile age of the specific accusation group: 52.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def question4(df):\n",
        "    # Filter for 2018 data only\n",
        "    df_2018 = df[df['Arrest Date'].dt.year == 2018].copy()\n",
        "\n",
        "    # Remove charge groups we don't want to include\n",
        "    excluded_groups = ['Pre-Delinquency', 'Non-Criminal Detention']\n",
        "    df_filtered = df_2018[~df_2018['Charge Group Description'].isin(excluded_groups)]\n",
        "\n",
        "    # Remove rows where charge group is missing or age is missing\n",
        "    df_clean = df_filtered[df_filtered['Charge Group Description'].notna()]\n",
        "    df_clean = df_clean[df_clean['Age'].notna()]\n",
        "\n",
        "    print(f\"Working with {len(df_clean)} records after filtering\")\n",
        "\n",
        "    # Calculate overall statistics\n",
        "    overall_age_mean = df_clean['Age'].mean()\n",
        "    overall_age_std = df_clean['Age'].std()\n",
        "\n",
        "    print(f\"Overall - Mean age: {overall_age_mean:.2f}, Std: {overall_age_std:.2f}\")\n",
        "\n",
        "    # We'll store z-scores for each charge group\n",
        "    z_scores = {}\n",
        "\n",
        "    # Calculate for each charge group\n",
        "    charge_groups = df_clean['Charge Group Description'].unique()\n",
        "\n",
        "    for charge in charge_groups:\n",
        "        group_data = df_clean[df_clean['Charge Group Description'] == charge]\n",
        "        n = len(group_data)\n",
        "\n",
        "        # Only calculate if we have enough data points\n",
        "        if n >= 10:\n",
        "            group_mean = group_data['Age'].mean()\n",
        "\n",
        "            # Standard error = standard deviation / sqrt(sample size)\n",
        "            standard_error = overall_age_std / (n ** 0.5)\n",
        "\n",
        "            # Z-score = (group_mean - overall_mean) / standard_error\n",
        "            if standard_error > 0:\n",
        "                z_score = (group_mean - overall_age_mean) / standard_error\n",
        "                z_scores[charge] = z_score\n",
        "\n",
        "    if not z_scores:\n",
        "        print(\"No valid z-scores calculated\")\n",
        "        return 0\n",
        "\n",
        "    # Find the largest absolute z-score\n",
        "    max_abs_z = 0\n",
        "    max_charge = None\n",
        "\n",
        "    for charge, z in z_scores.items():\n",
        "        abs_z = abs(z)\n",
        "        if abs_z > max_abs_z:\n",
        "            max_abs_z = abs_z\n",
        "            max_charge = charge\n",
        "\n",
        "    # Print some intermediate results to show my work\n",
        "    print(f\"\\nCalculated z-scores for {len(z_scores)} charge groups\")\n",
        "    print(f\"Largest absolute z-score: {max_abs_z:.4f}\")\n",
        "    print(f\"Charge group with largest z-score: {max_charge}\")\n",
        "\n",
        "    # Show a few examples\n",
        "    print(\"\\nSome examples:\")\n",
        "    sorted_charges = sorted(z_scores.items(), key=lambda x: abs(x[1]), reverse=True)\n",
        "    for i, (charge, z) in enumerate(sorted_charges[:3]):\n",
        "        group_data = df_clean[df_clean['Charge Group Description'] == charge]\n",
        "        print(f\"  {charge}: z = {z:.3f}, n = {len(group_data)}, mean age = {group_data['Age'].mean():.2f}\")\n",
        "\n",
        "    return max_abs_z\n",
        "\n",
        "# Run the analysis\n",
        "result = question4(df)\n",
        "print(f\"\\nFinal answer for question 4: {result:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12HO3nq_qr-8",
        "outputId": "bf91e935-76a8-4a39-b767-4fd42bb0b10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with 91544 records after filtering\n",
            "Overall - Mean age: 34.98, Std: 12.86\n",
            "\n",
            "Calculated z-scores for 25 charge groups\n",
            "Largest absolute z-score: 42.5711\n",
            "Charge group with largest z-score: Drunkeness\n",
            "\n",
            "Some examples:\n",
            "  Drunkeness: z = 42.571, n = 3769, mean age = 43.91\n",
            "  Liquor Laws: z = 34.393, n = 3481, mean age = 42.48\n",
            "  Robbery: z = -32.014, n = 2787, mean age = 27.18\n",
            "\n",
            "Final answer for question 4: 42.5711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def question5(df):\n",
        "    # Bradbury Building coordinates\n",
        "    bradbury_lat = 34.050536\n",
        "    bradbury_lon = -118.247861\n",
        "\n",
        "    print(\"Starting analysis for arrests near Bradbury Building...\")\n",
        "\n",
        "    # First, let's see what location data looks like\n",
        "    if 'Location' in df.columns:\n",
        "        print(f\"Location column found, first few values:\")\n",
        "        print(df['Location'].head())\n",
        "    else:\n",
        "        print(\"No Location column found, checking for latitude/longitude columns\")\n",
        "        # If no Location column, maybe there are separate lat/lon columns\n",
        "        if 'Latitude' in df.columns and 'Longitude' in df.columns:\n",
        "            print(\"Using existing Latitude and Longitude columns\")\n",
        "        else:\n",
        "            print(\"No location data available\")\n",
        "            return 0\n",
        "\n",
        "    # Try to extract coordinates from Location column if it exists\n",
        "    if 'Location' in df.columns:\n",
        "        # The Location column seems to have format (lat, lon)\n",
        "        # Let's extract the numbers\n",
        "        df_coords = df.copy()\n",
        "        coords_split = df_coords['Location'].str.extract(r'\\(([^,]+),\\s*([^)]+)\\)')\n",
        "        df_coords['Latitude'] = pd.to_numeric(coords_split[0], errors='coerce')\n",
        "        df_coords['Longitude'] = pd.to_numeric(coords_split[1], errors='coerce')\n",
        "    else:\n",
        "        df_coords = df.copy()\n",
        "\n",
        "    # Remove rows with missing or (0,0) coordinates\n",
        "    valid_locations = df_coords[\n",
        "        (df_coords['Latitude'].notna()) &\n",
        "        (df_coords['Longitude'].notna()) &\n",
        "        (df_coords['Latitude'] != 0) &\n",
        "        (df_coords['Longitude'] != 0)\n",
        "    ]\n",
        "\n",
        "    print(f\"\\nLocation data summary:\")\n",
        "    print(f\"Total records: {len(df)}\")\n",
        "    print(f\"Records with valid coordinates: {len(valid_locations)}\")\n",
        "    print(f\"Records missing/bad coordinates: {len(df) - len(valid_locations)}\")\n",
        "\n",
        "    if len(valid_locations) == 0:\n",
        "        print(\"No valid location data to analyze\")\n",
        "        return 0\n",
        "\n",
        "    # Show some coordinate ranges\n",
        "    print(f\"Latitude range: {valid_locations['Latitude'].min():.4f} to {valid_locations['Latitude'].max():.4f}\")\n",
        "    print(f\"Longitude range: {valid_locations['Longitude'].min():.4f} to {valid_locations['Longitude'].max():.4f}\")\n",
        "\n",
        "    # Calculate distances using the spherical Earth to plane projection\n",
        "    # This is the formula they mentioned in the question\n",
        "    earth_radius = 6371  # km\n",
        "\n",
        "    distances = []\n",
        "    close_incidents = 0\n",
        "\n",
        "    for idx, row in valid_locations.iterrows():\n",
        "        lat1 = math.radians(bradbury_lat)\n",
        "        lon1 = math.radians(bradbury_lon)\n",
        "        lat2 = math.radians(row['Latitude'])\n",
        "        lon2 = math.radians(row['Longitude'])\n",
        "\n",
        "        # Calculate differences\n",
        "        delta_lat = lat2 - lat1\n",
        "        # For longitude, account for latitude using average lat\n",
        "        delta_lon = (lon2 - lon1) * math.cos((lat1 + lat2) / 2)\n",
        "\n",
        "        # Straight-line distance on the projected plane\n",
        "        distance_km = earth_radius * math.sqrt(delta_lat**2 + delta_lon**2)\n",
        "        distances.append(distance_km)\n",
        "\n",
        "        if distance_km <= 2:\n",
        "            close_incidents += 1\n",
        "\n",
        "    # Add distances to dataframe for analysis\n",
        "    valid_locations = valid_locations.copy()\n",
        "    valid_locations['Distance_km'] = distances\n",
        "\n",
        "    print(f\"\\nDistance analysis:\")\n",
        "    print(f\"Minimum distance: {min(distances):.3f} km\")\n",
        "    print(f\"Maximum distance: {max(distances):.3f} km\")\n",
        "    print(f\"Average distance: {sum(distances)/len(distances):.3f} km\")\n",
        "    print(f\"Arrests within 2km: {close_incidents}\")\n",
        "\n",
        "    # Show some of the closest arrests\n",
        "    close_arrests = valid_locations[valid_locations['Distance_km'] <= 2]\n",
        "    if len(close_arrests) > 0:\n",
        "        print(f\"\\nSome arrests within 2km:\")\n",
        "        close_sample = close_arrests.head(3)\n",
        "        for i, (idx, row) in enumerate(close_sample.iterrows()):\n",
        "            address = row.get('Address', 'Address not available')\n",
        "            print(f\"  {i+1}. {row['Distance_km']:.2f} km - {address}\")\n",
        "\n",
        "    # Also check how many are very close (within 0.5km)\n",
        "    very_close = valid_locations[valid_locations['Distance_km'] <= 0.5]\n",
        "    print(f\"Arrests within 0.5km: {len(very_close)}\")\n",
        "\n",
        "    return close_incidents\n",
        "\n",
        "# Run the analysis\n",
        "print(\"=== Question 5: Arrests near Bradbury Building ===\")\n",
        "q5_result = question5(df)\n",
        "print(f\"\\nFinal answer for Q5: {q5_result} arrests within 2km of Bradbury Building\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mytzU65G3l4J",
        "outputId": "878acede-ed4d-491a-cd85-00aecd8713dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Question 5: Arrests near Bradbury Building ===\n",
            "Starting analysis for arrests near Bradbury Building...\n",
            "Location column found, first few values:\n",
            "151    (34.1006, -118.3417)\n",
            "152    (34.1006, -118.3417)\n",
            "153     (34.051, -118.3548)\n",
            "154    (33.9424, -118.2517)\n",
            "155    (34.0761, -118.3614)\n",
            "Name: Location, dtype: object\n",
            "\n",
            "Location data summary:\n",
            "Total records: 1231627\n",
            "Records with valid coordinates: 1230857\n",
            "Records missing/bad coordinates: 770\n",
            "Latitude range: 33.3427 to 34.8146\n",
            "Longitude range: -118.8513 to -117.7115\n",
            "\n",
            "Distance analysis:\n",
            "Minimum distance: 0.053 km\n",
            "Maximum distance: 91.752 km\n",
            "Average distance: 14.597 km\n",
            "Arrests within 2km: 130015\n",
            "\n",
            "Some arrests within 2km:\n",
            "  1. 1.06 km - SPRING\n",
            "  2. 0.58 km - SPRING                       ST\n",
            "  3. 1.09 km - 8TH                          ST\n",
            "Arrests within 0.5km: 10144\n",
            "\n",
            "Final answer for Q5: 130015 arrests within 2km of Bradbury Building\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def question6(df):\n",
        "\n",
        "    # Filter for 2018 data\n",
        "    df_2018 = df[df['Arrest Date'].dt.year == 2018].copy()\n",
        "    print(f\"Total arrests in 2018: {len(df_2018)}\")\n",
        "\n",
        "    # Look for Pico Boulevard addresses\n",
        "    pico_mask = df_2018['Address'].str.contains('PICO', case=False, na=False)\n",
        "    pico_arrests = df_2018[pico_mask]\n",
        "\n",
        "    print(f\"Found {len(pico_arrests)} arrests with 'Pico' in address\")\n",
        "\n",
        "    if len(pico_arrests) == 0:\n",
        "        print(\"No Pico Boulevard arrests found\")\n",
        "        return 0\n",
        "\n",
        "    # Show some example addresses to make sure we're getting the right data\n",
        "    print(\"\\nSample Pico addresses:\")\n",
        "    for i, addr in enumerate(pico_arrests['Address'].head(3)):\n",
        "        print(f\"  {i+1}. {addr}\")\n",
        "\n",
        "    # Extract coordinates from Location column\n",
        "    if 'Location' not in df.columns:\n",
        "        print(\"No Location column found!\")\n",
        "        return 0\n",
        "\n",
        "    # Parse the Location column - it seems to be in format (lat, lon)\n",
        "    locations = pico_arrests['Location'].str.extract(r'\\(([^,]+),\\s*([^)]+)\\)')\n",
        "    pico_arrests = pico_arrests.copy()\n",
        "    pico_arrests['Latitude'] = pd.to_numeric(locations[0], errors='coerce')\n",
        "    pico_arrests['Longitude'] = pd.to_numeric(locations[1], errors='coerce')\n",
        "\n",
        "    # Remove rows with missing coordinates\n",
        "    valid_coords = pico_arrests.dropna(subset=['Latitude', 'Longitude'])\n",
        "    print(f\"\\nArrests with valid coordinates: {len(valid_coords)}\")\n",
        "\n",
        "    if len(valid_coords) < 5:\n",
        "        print(\"Not enough data points for analysis\")\n",
        "        return 0\n",
        "\n",
        "    # Show coordinate ranges\n",
        "    print(f\"Latitude range: {valid_coords['Latitude'].min():.4f} to {valid_coords['Latitude'].max():.4f}\")\n",
        "    print(f\"Longitude range: {valid_coords['Longitude'].min():.4f} to {valid_coords['Longitude'].max():.4f}\")\n",
        "\n",
        "    # Remove outliers - 2 standard deviations from mean\n",
        "    lat_mean = valid_coords['Latitude'].mean()\n",
        "    lat_std = valid_coords['Latitude'].std()\n",
        "    lon_mean = valid_coords['Longitude'].mean()\n",
        "    lon_std = valid_coords['Longitude'].std()\n",
        "\n",
        "    print(f\"\\nCoordinate statistics:\")\n",
        "    print(f\"Latitude - mean: {lat_mean:.4f}, std: {lat_std:.4f}\")\n",
        "    print(f\"Longitude - mean: {lon_mean:.4f}, std: {lon_std:.4f}\")\n",
        "\n",
        "    # Filter out outliers\n",
        "    no_outliers = valid_coords[\n",
        "        (valid_coords['Latitude'] >= lat_mean - 2*lat_std) &\n",
        "        (valid_coords['Latitude'] <= lat_mean + 2*lat_std) &\n",
        "        (valid_coords['Longitude'] >= lon_mean - 2*lon_std) &\n",
        "        (valid_coords['Longitude'] <= lon_mean + 2*lon_std)\n",
        "    ]\n",
        "\n",
        "    print(f\"After removing outliers: {len(no_outliers)} arrests\")\n",
        "\n",
        "    if len(no_outliers) < 2:\n",
        "        print(\"Not enough points left after outlier removal\")\n",
        "        return 0\n",
        "\n",
        "    # Find the endpoints of Pico Boulevard\n",
        "    # Since it runs mostly east-west, we'll use longitude to find endpoints\n",
        "    west_idx = no_outliers['Longitude'].idxmin()\n",
        "    east_idx = no_outliers['Longitude'].idxmax()\n",
        "\n",
        "    west_point = no_outliers.loc[west_idx]\n",
        "    east_point = no_outliers.loc[east_idx]\n",
        "\n",
        "    print(f\"\\nEndpoints of Pico Boulevard:\")\n",
        "    print(f\"Western point: ({west_point['Latitude']:.4f}, {west_point['Longitude']:.4f})\")\n",
        "    print(f\"  Address: {west_point['Address']}\")\n",
        "    print(f\"Eastern point: ({east_point['Latitude']:.4f}, {east_point['Longitude']:.4f})\")\n",
        "    print(f\"  Address: {east_point['Address']}\")\n",
        "\n",
        "    # Calculate distance between endpoints using the same method as Q5\n",
        "    earth_radius = 6371  # km\n",
        "\n",
        "    lat1 = math.radians(west_point['Latitude'])\n",
        "    lon1 = math.radians(west_point['Longitude'])\n",
        "    lat2 = math.radians(east_point['Latitude'])\n",
        "    lon2 = math.radians(east_point['Longitude'])\n",
        "\n",
        "    delta_lat = lat2 - lat1\n",
        "    delta_lon = (lon2 - lon1) * math.cos((lat1 + lat2) / 2)\n",
        "\n",
        "    boulevard_length = earth_radius * math.sqrt(delta_lat**2 + delta_lon**2)\n",
        "\n",
        "    print(f\"\\nBoulevard length calculation:\")\n",
        "    print(f\"Estimated length of Pico Boulevard: {boulevard_length:.2f} km\")\n",
        "\n",
        "    # Calculate arrests per kilometer\n",
        "    arrests_count = len(no_outliers)\n",
        "    arrests_per_km = arrests_count / boulevard_length\n",
        "\n",
        "    print(f\"\\nFinal calculation:\")\n",
        "    print(f\"Total arrests on Pico: {arrests_count}\")\n",
        "    print(f\"Boulevard length: {boulevard_length:.2f} km\")\n",
        "    print(f\"Arrests per km: {arrests_per_km:.2f}\")\n",
        "\n",
        "    # Let's also check if this seems reasonable\n",
        "    print(f\"\\nSanity check - average distance between points:\")\n",
        "    # Calculate average spacing\n",
        "    avg_spacing = boulevard_length / arrests_count if arrests_count > 0 else 0\n",
        "    print(f\"Average spacing: {avg_spacing:.2f} km between arrests\")\n",
        "\n",
        "    return arrests_per_km\n",
        "\n",
        "# Run the analysis\n",
        "print(\"Starting Pico Boulevard analysis...\")\n",
        "q6_result = question6(df)\n",
        "\n",
        "print(f\"Q6. Arrests per kilometer on Pico Boulevard: {q6_result:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwa0n8V44QIb",
        "outputId": "3f48bcd5-08c5-49a5-d494-7dc6c08003d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Pico Boulevard analysis...\n",
            "=== Question 6: Arrests per km on Pico Boulevard ===\n",
            "\n",
            "Total arrests in 2018: 104277\n",
            "Found 613 arrests with 'Pico' in address\n",
            "\n",
            "Sample Pico addresses:\n",
            "  1. PICO                         BL\n",
            "  2. PICO                         BL\n",
            "  3. PICO                         BL\n",
            "\n",
            "Arrests with valid coordinates: 613\n",
            "Latitude range: 33.9786 to 34.2567\n",
            "Longitude range: -118.5689 to -118.1739\n",
            "\n",
            "Coordinate statistics:\n",
            "Latitude - mean: 34.0433, std: 0.0124\n",
            "Longitude - mean: -118.3499, std: 0.0690\n",
            "After removing outliers: 605 arrests\n",
            "\n",
            "Endpoints of Pico Boulevard:\n",
            "Western point: (34.0281, -118.4530)\n",
            "  Address: PICO                         BL\n",
            "Eastern point: (34.0188, -118.2159)\n",
            "  Address: 3000 E  PICO                         BL\n",
            "\n",
            "Boulevard length calculation:\n",
            "Estimated length of Pico Boulevard: 21.88 km\n",
            "\n",
            "Final calculation:\n",
            "Total arrests on Pico: 605\n",
            "Boulevard length: 21.88 km\n",
            "Arrests per km: 27.66\n",
            "\n",
            "Sanity check - average distance between points:\n",
            "Average spacing: 0.04 km between arrests\n",
            "\n",
            "=== FINAL ANSWER Q6 ===\n",
            "Arrests per kilometer on Pico Boulevard: 27.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def question7(df):\n",
        "\n",
        "    # First, let's understand the data we're working with\n",
        "    print(\"Initial data overview:\")\n",
        "    print(f\"Total records: {len(df)}\")\n",
        "    print(f\"Columns available: {list(df.columns)}\")\n",
        "\n",
        "    # Filter for records before 2019\n",
        "    df_pre2019 = df[df['Arrest Date'] < '2019-01-01']\n",
        "    print(f\"Records before 2019: {len(df_pre2019)}\")\n",
        "\n",
        "    # Check for missing charge group codes and Area IDs\n",
        "    missing_charge = df_pre2019['Charge Group Code'].isna().sum()\n",
        "    missing_area = df_pre2019['Area ID'].isna().sum()\n",
        "    print(f\"Records missing charge code: {missing_charge}\")\n",
        "    print(f\"Records missing area ID: {missing_area}\")\n",
        "\n",
        "    # Filter out records without charge group code or area ID\n",
        "    valid_data = df_pre2019[\n",
        "        (df_pre2019['Charge Group Code'].notna()) &\n",
        "        (df_pre2019['Area ID'].notna())\n",
        "    ].copy()\n",
        "\n",
        "    # Also remove charge group code 99 as specified\n",
        "    valid_data = valid_data[valid_data['Charge Group Code'] != 99]\n",
        "\n",
        "    print(f\"Valid records for analysis: {len(valid_data)}\")\n",
        "\n",
        "    if len(valid_data) == 0:\n",
        "        print(\"No valid data to analyze\")\n",
        "        return 0\n",
        "\n",
        "    # Let's see what charge groups and areas we have\n",
        "    charge_counts = valid_data['Charge Group Code'].value_counts()\n",
        "    area_counts = valid_data['Area ID'].value_counts()\n",
        "\n",
        "    print(f\"\\nCharge group distribution (top 5):\")\n",
        "    for code, count in charge_counts.head().items():\n",
        "        print(f\"Code {code}: {count} arrests ({count/len(valid_data):.1%})\")\n",
        "\n",
        "    print(f\"\\nArea distribution (top 5):\")\n",
        "    for area, count in area_counts.head().items():\n",
        "        print(f\"Area {area}: {count} arrests ({count/len(valid_data):.1%})\")\n",
        "\n",
        "    # Calculate city-wide probabilities for each charge group\n",
        "    total_city_arrests = len(valid_data)\n",
        "    city_charge_counts = valid_data['Charge Group Code'].value_counts()\n",
        "    city_probs = {}\n",
        "\n",
        "    for charge_code, count in city_charge_counts.items():\n",
        "        city_probs[charge_code] = count / total_city_arrests\n",
        "\n",
        "    print(f\"\\nCity-wide probabilities calculated for {len(city_probs)} charge groups\")\n",
        "\n",
        "    # Now calculate ratios for each area-charge combination\n",
        "    ratios = []\n",
        "    area_charge_combinations = []\n",
        "\n",
        "    areas_analyzed = 0\n",
        "    combinations_analyzed = 0\n",
        "\n",
        "    for area_id in valid_data['Area ID'].unique():\n",
        "        area_data = valid_data[valid_data['Area ID'] == area_id]\n",
        "        area_total = len(area_data)\n",
        "\n",
        "        # Skip areas with very few arrests\n",
        "        if area_total < 50:\n",
        "            continue\n",
        "\n",
        "        areas_analyzed += 1\n",
        "\n",
        "        for charge_code in area_data['Charge Group Code'].unique():\n",
        "            charge_in_area = len(area_data[area_data['Charge Group Code'] == charge_code])\n",
        "\n",
        "            # Only consider if we have enough data points\n",
        "            if charge_in_area >= 10:\n",
        "                # Calculate probability in this area\n",
        "                prob_in_area = charge_in_area / area_total\n",
        "\n",
        "                # Get city-wide probability\n",
        "                prob_citywide = city_probs.get(charge_code, 0)\n",
        "\n",
        "                # Avoid division by zero and very small probabilities\n",
        "                if prob_citywide > 0.0001:\n",
        "                    ratio = prob_in_area / prob_citywide\n",
        "                    ratios.append(ratio)\n",
        "                    area_charge_combinations.append((area_id, charge_code, ratio))\n",
        "                    combinations_analyzed += 1\n",
        "\n",
        "    print(f\"\\nAnalysis results:\")\n",
        "    print(f\"Areas analyzed: {areas_analyzed}\")\n",
        "    print(f\"Area-charge combinations analyzed: {combinations_analyzed}\")\n",
        "\n",
        "    if len(ratios) == 0:\n",
        "        print(\"No valid ratios calculated\")\n",
        "        return 0\n",
        "\n",
        "    # Show some statistics about the ratios\n",
        "    print(f\"Ratio statistics:\")\n",
        "    print(f\"Minimum ratio: {min(ratios):.2f}\")\n",
        "    print(f\"Maximum ratio: {max(ratios):.2f}\")\n",
        "    print(f\"Average ratio: {sum(ratios)/len(ratios):.2f}\")\n",
        "\n",
        "    # Find the top 5 ratios\n",
        "    sorted_combinations = sorted(area_charge_combinations, key=lambda x: x[2], reverse=True)\n",
        "    top_5 = sorted_combinations[:5]\n",
        "\n",
        "    print(f\"\\nTop 5 disproportionate area-charge combinations:\")\n",
        "    for i, (area, charge, ratio) in enumerate(top_5, 1):\n",
        "        area_count = len(valid_data[valid_data['Area ID'] == area])\n",
        "        charge_count = len(valid_data[valid_data['Charge Group Code'] == charge])\n",
        "        charge_in_area = len(valid_data[(valid_data['Area ID'] == area) &\n",
        "                                      (valid_data['Charge Group Code'] == charge)])\n",
        "\n",
        "        print(f\"{i}. Area {area}, Charge {charge}: ratio = {ratio:.2f}\")\n",
        "        print(f\"   ({charge_in_area}/{area_count} in area vs {charge_count}/{total_city_arrests} city-wide)\")\n",
        "\n",
        "    # Calculate average of top 5 ratios\n",
        "    top_5_ratios = [ratio for _, _, ratio in top_5]\n",
        "    average_top_5 = sum(top_5_ratios) / len(top_5_ratios)\n",
        "\n",
        "    print(f\"\\nAverage of top 5 ratios: {average_top_5:.2f}\")\n",
        "\n",
        "    # Let's also check what the ratios mean\n",
        "    print(f\"\\nInterpretation:\")\n",
        "    print(f\"A ratio of {average_top_5:.1f} means these charge groups occur\")\n",
        "    print(f\"{average_top_5:.1f} times more often in these areas than expected city-wide\")\n",
        "\n",
        "    return average_top_5\n",
        "\n",
        "# Run the analysis\n",
        "print(\"Starting disproportionate rate analysis...\")\n",
        "q7_result = question7(df)\n",
        "\n",
        "print(f\"Q7. Average of top 5 ratios: {q7_result:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxfctDTV4dYn",
        "outputId": "12a52021-2b6f-4663-ffdb-cd2a28a92917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting disproportionate rate analysis...\n",
            "=== Question 7: Disproportionate Arrest Rates ===\n",
            "\n",
            "Initial data overview:\n",
            "Total records: 1231627\n",
            "Columns available: ['Report ID', 'Arrest Date', 'Time', 'Area ID', 'Area Name', 'Reporting District', 'Age', 'Sex Code', 'Descent Code', 'Charge Group Code', 'Charge Group Description', 'Arrest Type Code', 'Charge', 'Charge Description', 'Address', 'Cross Street', 'Location', 'Latitude', 'Longitude']\n",
            "Records before 2019: 1231627\n",
            "Records missing charge code: 79907\n",
            "Records missing area ID: 0\n",
            "Valid records for analysis: 1151713\n",
            "\n",
            "Charge group distribution (top 5):\n",
            "Code 24.0: 229826 arrests (20.0%)\n",
            "Code 16.0: 153432 arrests (13.3%)\n",
            "Code 18.0: 113420 arrests (9.8%)\n",
            "Code 22.0: 112996 arrests (9.8%)\n",
            "Code 4.0: 77964 arrests (6.8%)\n",
            "\n",
            "Area distribution (top 5):\n",
            "Area 1: 116368 arrests (10.1%)\n",
            "Area 6: 102986 arrests (8.9%)\n",
            "Area 14: 74641 arrests (6.5%)\n",
            "Area 12: 65701 arrests (5.7%)\n",
            "Area 3: 63703 arrests (5.5%)\n",
            "\n",
            "City-wide probabilities calculated for 28 charge groups\n",
            "\n",
            "Analysis results:\n",
            "Areas analyzed: 21\n",
            "Area-charge combinations analyzed: 571\n",
            "Ratio statistics:\n",
            "Minimum ratio: 0.06\n",
            "Maximum ratio: 5.32\n",
            "Average ratio: 1.03\n",
            "\n",
            "Top 5 disproportionate area-charge combinations:\n",
            "1. Area 1, Charge 20.0: ratio = 5.32\n",
            "   (19480/116368 in area vs 36264/1151713 city-wide)\n",
            "2. Area 17, Charge 19.0: ratio = 3.19\n",
            "   (292/36660 in area vs 2878/1151713 city-wide)\n",
            "3. Area 14, Charge 29.0: ratio = 3.17\n",
            "   (93/74641 in area vs 452/1151713 city-wide)\n",
            "4. Area 17, Charge 6.0: ratio = 3.01\n",
            "   (6354/36660 in area vs 66257/1151713 city-wide)\n",
            "5. Area 9, Charge 13.0: ratio = 2.88\n",
            "   (5649/61337 in area vs 36780/1151713 city-wide)\n",
            "\n",
            "Average of top 5 ratios: 3.52\n",
            "\n",
            "Interpretation:\n",
            "A ratio of 3.5 means these charge groups occur\n",
            "3.5 times more often in these areas than expected city-wide\n",
            "\n",
            "=== FINAL ANSWER Q7 ===\n",
            "Average of top 5 ratios: 3.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9dSh9m85Ngp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}